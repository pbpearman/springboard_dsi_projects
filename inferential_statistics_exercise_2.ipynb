{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Examining racial discrimination in the US job market\n",
    "\n",
    "#### Background\n",
    "Racial discrimination continues to be pervasive in cultures throughout the world. Researchers examined the level of racial discrimination in the United States labor market by randomly assigning identical résumés black-sounding or white-sounding names and observing the impact on requests for interviews from employers.\n",
    "\n",
    "#### Data\n",
    "In the dataset provided, each row represents a resume. The 'race' column has two values, 'b' and 'w', indicating black-sounding and white-sounding. The column 'call' has two values, 1 and 0, indicating whether the resume received a call from employers or not.\n",
    "\n",
    "Note that the 'b' and 'w' values in race are assigned randomly to the resumes.\n",
    "\n",
    "#### Exercise\n",
    "You will perform a statistical analysis to establish whether race has a significant impact on the rate of callbacks for resumes.\n",
    "\n",
    "Answer the following questions **in this notebook below and submit to your Github account**. \n",
    "\n",
    "   1. What test is appropriate for this problem? Does CLT apply?\n",
    "   2. What are the null and alternate hypotheses?\n",
    "   3. Compute margin of error, confidence interval, and p-value.\n",
    "   4. Discuss statistical significance.\n",
    "\n",
    "You can include written notes in notebook cells using Markdown: \n",
    "   - In the control panel at the top, choose Cell > Cell Type > Markdown\n",
    "   - Markdown syntax: http://nestacms.com/docs/creating-content/markdown-cheat-sheet\n",
    "\n",
    "\n",
    "#### Resources\n",
    "+ Experiment information and data source: http://www.povertyactionlab.org/evaluation/discrimination-job-market-united-states\n",
    "+ Scipy statistical methods: http://docs.scipy.org/doc/scipy/reference/stats.html \n",
    "+ Markdown syntax: http://nestacms.com/docs/creating-content/markdown-cheat-sheet\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>body {\n",
       "    margin: 0;\n",
       "    font-family: Helvetica;\n",
       "}\n",
       "table.dataframe {\n",
       "    border-collapse: collapse;\n",
       "    border: none;\n",
       "}\n",
       "table.dataframe tr {\n",
       "    border: none;\n",
       "}\n",
       "table.dataframe td, table.dataframe th {\n",
       "    margin: 0;\n",
       "    border: 1px solid white;\n",
       "    padding-left: 0.25em;\n",
       "    padding-right: 0.25em;\n",
       "}\n",
       "table.dataframe th:not(:empty) {\n",
       "    background-color: #fec;\n",
       "    text-align: left;\n",
       "    font-weight: normal;\n",
       "}\n",
       "table.dataframe tr:nth-child(2) th:empty {\n",
       "    border-left: none;\n",
       "    border-right: 1px dashed #888;\n",
       "}\n",
       "table.dataframe td {\n",
       "    border: 2px solid #ccf;\n",
       "    background-color: #f4f4ff;\n",
       "}\n",
       "h3 {\n",
       "    color: white;\n",
       "    background-color: black;\n",
       "    padding: 0.5em;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "css = open('style-table.css').read() + open('style-notebook.css').read()\n",
    "HTML('<style>{}</style>'.format(css))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.io.stata.read_stata('data/us_job_market_discrimination.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of callbacks for black-sounding names\n",
    "sum(data[data.race=='b'].call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'id', u'ad', u'education', u'ofjobs', u'yearsexp', u'honors',\n",
       "       u'volunteer', u'military', u'empholes', u'occupspecific', u'occupbroad',\n",
       "       u'workinschool', u'email', u'computerskills', u'specialskills',\n",
       "       u'firstname', u'sex', u'race', u'h', u'l', u'call', u'city', u'kind',\n",
       "       u'adid', u'fracblack', u'fracwhite', u'lmedhhinc', u'fracdropout',\n",
       "       u'fraccolp', u'linc', u'col', u'expminreq', u'schoolreq', u'eoe',\n",
       "       u'parent_sales', u'parent_emp', u'branch_sales', u'branch_emp', u'fed',\n",
       "       u'fracblack_empzip', u'fracwhite_empzip', u'lmedhhinc_empzip',\n",
       "       u'fracdropout_empzip', u'fraccolp_empzip', u'linc_empzip', u'manager',\n",
       "       u'supervisor', u'secretary', u'offsupport', u'salesrep', u'retailsales',\n",
       "       u'req', u'expreq', u'comreq', u'educreq', u'compreq', u'orgreq',\n",
       "       u'manuf', u'transcom', u'bankreal', u'trade', u'busservice',\n",
       "       u'othservice', u'missind', u'ownership'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=data.groupby(['call','race']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1=df.unstack('race')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1. Does the CLT apply? What test is appropriate?\n",
    "#### Answer: With only values of '1' or '0', this is not a normally distributed variable.  It is, in fact a Bernoulli variable, and these are count data.  Therefore, a 2x2 contingency test could be appropriate, but the column totals are fixed. This is not simple count data from a population.  So instead, one can develop statistics describing the uncertainty around the proportions of invited applicants, and compare them.  If one were to repeately sample these proportions, one could anticipate that the average value of the proportion would converge on the parametric value of the proportion, due to the CLT.  Thus, we can develop standard statistical testing  based on the sampling distributions of the proportions, and their difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2. What are the null and alternate hypotheses?\n",
    "#### Answer: H<sub>0</sub> is that the two proportions are the same and, thus, that their difference equals 0.  \n",
    "#### H<sub>0</sub>: P1 - P2 == 0 ; H<sub>1</sub>: P1 - P2 !=0.   \n",
    "Let's refer to this difference as the test statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>race</th>\n",
       "      <th>b</th>\n",
       "      <th>w</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>call</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>2278</td>\n",
       "      <td>2200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>157</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "race     b     w\n",
       "call            \n",
       "0.0   2278  2200\n",
       "1.0    157   235"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1       # Here are the counts of the cases in their categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "race\n",
       "b    2435\n",
       "w    2435\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sums=df1.apply(np.sum,axis=0)\n",
    "tot=np.sum(df1.apply(np.sum,axis=0))\n",
    "freq=df1.apply(np.sum,axis=1)/tot\n",
    "sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>race</th>\n",
       "      <th>b</th>\n",
       "      <th>w</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>call</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.935524</td>\n",
       "      <td>0.903491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.064476</td>\n",
       "      <td>0.096509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "race         b         w\n",
       "call                    \n",
       "0.0   0.935524  0.903491\n",
       "1.0   0.064476  0.096509"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "props=df1/sums    #The proportions of blacks (b) and whites (w) called back (call==1) are shown in this table\n",
    "props"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Finding the standard error of the test statistic, and generating the 97.5 %and 2.5% confidence intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here are the variances of each of the sampling distributions of the two proportions in the bottom row of the table just above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "race\n",
       "b    0.000025\n",
       "w    0.000036\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars=(props.iloc[0,:]*props.iloc[1,:])/sums  # Here are the variances of sampling distributions of each of the two\n",
    "vars                                         # proportions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The varances of the sampling distribution of the two proportions can be used to generate standard error of the test statistic, 'sd' below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0077833705866767553"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd=np.sqrt(vars.sum())  \n",
    "sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Here is the distance from the observed mean of P1-P2  that will span 95% of the test statistic's sampling distribution. One multiplies the Z value for the 2.5 % tail of the normal distribution by the standard error of the sampling distribution of the test statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01525540634988644"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d= 1.96*sd  \n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Of course, we need the observed value of the test statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.032032854209445585"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_stat=props.iloc[1,1] - props.iloc[1,0]  # The calculation of the observed value of the test statistic\n",
    "test_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding and subtracting the value 'd' from the test_stat provides the upper and lower limits of the confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lower limit is  0.0167774478596\n",
      "The upper limit is  0.0472882605593\n"
     ]
    }
   ],
   "source": [
    "lower= test_stat-d\n",
    "upper= test_stat+d\n",
    "print \"The lower limit is \", lower\n",
    "print \"The upper limit is \", upper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conducting a test of statistical signficance means determining the sampling distribution of the test statistic under the assumption of the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The best estimate of proportion called back under H0 is the mean of the two proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call\n",
      "0.0    4478\n",
      "1.0     392\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df1a=df1.apply(np.sum,axis=1)\n",
    "print df1a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.080492813141683772"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_null=df1a.loc[1.0]/float(df1a.sum())  \n",
    "p_null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here is the standard error of the sampling distribution of the test statistic under H<sub>0</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0077968940361704568"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se=np.sqrt((2*p_null*(1-p_null))/sums.iloc[0])\n",
    "se"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We want to conduct a 2-tailed test of whether the difference between the test statistic and it's value assumed under H0 (i.e. zero) is rare under H0.  So we want to find the z value corresponding to the observed difference, given the sampling distribution of the test statistic under H0.  This is straightforward now that we have the standard error of the test statistic under H<sub>0</sub>.  We simply divide the difference between the test statistic and its expected value under H<sub>0</sub> (which is zero) by the standard error we just calculated.  In this case, the corresponding value of z for the 5% tail of the normal distribution is 1.96.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.1084121524343464"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=test_stat/se     #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We see that the observed difference between the value of the test statistic and zero (its expected value under H<sub>0</sub>) is much further out on the tail of the distribution than would be expected.  We therefore reject the null hypothesis and conclude that the proportion of applicants with african-american sounding names that gets called is different than the proportion of applicants with non-african american sounding names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To get the p-value, one has to double the value given by the cdf of the normal distribution because we want the probability that lies in both tails of the distribution.  In fact, one minus the value from the CDF function only gives us the proportion in the right hand tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The value of P is  4.1315013825e-05\n"
     ]
    }
   ],
   "source": [
    "P= 2*(1-stats.norm.cdf(4.1,loc=0,scale=1))\n",
    "print \"The value of P is \",P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Discuss statistical significance\n",
    "#### Just briefly, this result is highly statistically significant.  A P-value of 0.00004 means that it is highly unlikely that such a difference in the proportion of call-backs would arise by chance in samples of over 2300 people assigned either 'b' or 'w'-sounding names.  In fact the propability of such a result is about than 4 in 100,000.  This result supports the contention that racial bias exists in this sample of evaluated job applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
